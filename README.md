# YouTube Video Transcript Analyzer 

Welcome to the **DataViz-YT_API_LexCIA_VideoIntel** repository. This repository contains a Python-based data science project that leverages the YouTube Data API and the YouTube Transcript API for extracting, analyzing, and visualizing YouTube video transcript and comment data. 

## Description

The main purpose of this project is to derive insights from YouTube video transcripts using Natural Language Processing (NLP) techniques and machine learning algorithms. The project contains several key features:

1. **Caption Extraction**: Retrieves both automatic and manual captions of a YouTube video.
2. **Transcript Extraction**: Generates the transcript of a YouTube video.
3. **Transcript Preprocessing**: Performs text cleaning and preprocessing on the transcripts.
4. **Data Analysis**: Conducts various types of analyses such as word frequency analysis, topic distribution, sentiment analysis, speaker contribution analysis, and named entity recognition.
5. **Data Visualization**: Creates informative visualizations to better understand the derived insights.
6. **Topic Modeling**: Implements Latent Dirichlet Allocation (LDA) for classifying text in a document to a specific topic.

---
## Visualizations

Here are some of the visualizations generated by this project:

### Reddit Comment Length vs Sentiment Comparison
![Reddit Comment Length vs Sentiment Comparison](screenshots/reddit_comment_length_sentiment_comparison_scatter_plot.png)

### Sentiment Distribution in Reddit Comments
![Sentiment Distribution in Reddit Comments](screenshots/sentiment_distribution_reddit_comments_pie_chart.png)

### Top 20 Keywords in Reddit Comments
![Top 20 Keywords in Reddit Comments](screenshots/Top_20_keywords_reddit_comments_barchart.png)

### Top 20 Most Frequent Words
![Top 20 Most Frequent Words](screenshots/Top_20_most-frequent_words.png)

### Top Keywords
![Top Keywords](screenshots/Top_keywords_barchart.png)

### Top Named Entities
![Top Named Entities](screenshots/Top_named_entities_barchart.png)

### Topic Distribution
![Topic Distribution](screenshots/Topic_distribution_pie_chart.png)

### Topic Duration
![Topic Duration](screenshots/Topic_duration_barchart.png)

### Word Cloud of Frequent Words
![Word Cloud of Frequent Words](screenshots/Word_cloud_frequent_words.png)

### YouTube Comment Enhanced Sentiment Score Frequency
![YouTube Comment Enhanced Sentiment Score Frequency](screenshots/YT_comment_enhanced_sentiment_score_frequency_barchart.png)

### YouTube Comment Length by Sentiment
![YouTube Comment Length by Sentiment](screenshots/YT_comment_length_by_sentiment_barchart.png)

### YouTube Comment Length Frequency Comparison
![YouTube Comment Length Frequency Comparison](screenshots/YT_comment_length_frequency_comparison_barchart.png)

### YouTube Comment Length vs Sentiment Comparison
![YouTube Comment Length vs Sentiment Comparison](screenshots/YT_comment_length_sentiment_comparison_scatter_plot.png)

### YouTube Comment Length vs Sentiment Score
![YouTube Comment Length vs Sentiment Score](screenshots/YT_comment_length_vs_sentiment_score_scatter_plot.png)

### YouTube Comment Sentiment Score Frequency
![YouTube Comment Sentiment Score Frequency](screenshots/YT_comment_sentiment_score_frequency_barchart.png)

### YouTube Comments Sentiment Scores with Mood Representative Colors
![YouTube Comments Sentiment Scores with Mood Representative Colors](screenshots/YT_comments_sentiment_scores_with_mood_representative_colors_boxplot.png)

### YouTube Comments Word Cloud
![YouTube Comments Word Cloud](screenshots/YT_comments_word_cloud.png)

---

## Installation

To install the necessary dependencies for this project, run the following command:

```bash
pip install youtube_transcript_api requests json nltk spacy gensim pyLDAvis plotly
```
## Usage

To use this project, upload the Jupyter notebook to your Jupyter Notebook environment or any IDE that supports .ipynb files. Ensure you have a valid YouTube Data API key for extracting video captions.

## Contributing

This repository is open-source. We warmly welcome contributions to enhance the functionality and efficiency of the code. If you're interested in contributing, please open an issue first to discuss the proposed changes.

## Visibility

This repository is set to **Private**. Only chosen collaborators can view and commit to this repository.

## License

The license for this project hasn't been defined yet. Refer to the **License** section to understand permissions regarding this code.

## Additional Files

This repository is initialized with a README and a .gitignore file. The .gitignore file specifies which file or file types Git should disregard. Check it for a list of ignored files.

For a comprehensive understanding of the project, we recommend going through the Jupyter notebook file.

---

Created by the ML-YouTubeTranscriptAnalyzer team.
